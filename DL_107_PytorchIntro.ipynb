{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL 107_PytorchIntro.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/4deepprk/4deepprk.github.io/blob/master/DL_107_PytorchIntro.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KPqFTlOiiiKv",
        "colab_type": "text"
      },
      "source": [
        "## Outline\n",
        "* PyTorch\n",
        "* What are tensors\n",
        "* Initialising, slicing, reshaping tensors\n",
        "* Numpy and PyTorch interfacing\n",
        "* GPU support for PyTorch + Enabling GPUs on Google Colab\n",
        "* Speed comparisons, Numpy -- PyTorch -- PyTorch on GPU\n",
        "* Autodiff concepts and application\n",
        "* Writing a basic learning loop using autograd\n",
        "* Exercises"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j4wIFDnRakTz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WJyLCI8PcPZq",
        "colab_type": "text"
      },
      "source": [
        "## Initialise tensors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NV2jveDIayX-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "96c02508-5538-4788-bb5e-330c84a080f1"
      },
      "source": [
        "x = torch.ones(3, 2)\n",
        "print(x)\n",
        "x = torch.zeros(3, 2)\n",
        "print(x)\n",
        "x = torch.rand(3, 2)\n",
        "print(x)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1., 1.],\n",
            "        [1., 1.],\n",
            "        [1., 1.]])\n",
            "tensor([[0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 0.]])\n",
            "tensor([[0.2786, 0.3343],\n",
            "        [0.3028, 0.1829],\n",
            "        [0.0640, 0.3349]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BuAQVNaPFN1P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "ca0f0ea0-6533-46cb-9b0d-4d00fb4cf44c"
      },
      "source": [
        "x = torch.empty(3, 2)\n",
        "print(x)\n",
        "y = torch.zeros_like(x)\n",
        "print(y)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[2.4205e-35, 0.0000e+00],\n",
            "        [3.3631e-44, 0.0000e+00],\n",
            "        [       nan, 0.0000e+00]])\n",
            "tensor([[0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 0.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bWrOMr-hFbwo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c5676818-1481-4aae-cb6d-46581230cd85"
      },
      "source": [
        "x = torch.linspace(0, 1, steps=5)\n",
        "print(x)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0.0000, 0.2500, 0.5000, 0.7500, 1.0000])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_QspfvYEtuB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "ada1f7bb-a8a8-46ff-9040-d20f4253558e"
      },
      "source": [
        "x = torch.tensor([[1, 2], \n",
        "                 [3, 4], \n",
        "                 [5, 6]])\n",
        "print(x)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1, 2],\n",
            "        [3, 4],\n",
            "        [5, 6]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wKub-KJLcSDJ",
        "colab_type": "text"
      },
      "source": [
        "## Slicing tensors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UxSlfSVrbH8h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "7a1ee14f-7a76-4b01-e75b-7c68f22d4b66"
      },
      "source": [
        "print(x.size())\n",
        "print(x[:, 1]) \n",
        "print(x[0, :]) "
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([3, 2])\n",
            "tensor([2, 4, 6])\n",
            "tensor([1, 2])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AGWkj2utcrz9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "c4480a7d-5cb6-4e08-89a9-3720ffdc7b9c"
      },
      "source": [
        "y = x[1, 1]\n",
        "print(y)\n",
        "print(y.item())"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(4)\n",
            "4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6YvWGrX0cUpf",
        "colab_type": "text"
      },
      "source": [
        "## Reshaping tensors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mn1q-Hm7b6hP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "5631689c-16d6-4020-829d-0086cbeb463f"
      },
      "source": [
        "print(x)\n",
        "y = x.view(2, 3)\n",
        "print(y)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1, 2],\n",
            "        [3, 4],\n",
            "        [5, 6]])\n",
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1EbIwPvBF4Lg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "73bab664-8bf4-407b-df42-6c7d92b7115b"
      },
      "source": [
        "y = x.view(6,-1) \n",
        "print(y)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1],\n",
            "        [2],\n",
            "        [3],\n",
            "        [4],\n",
            "        [5],\n",
            "        [6]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2XxOq0ObdXEC",
        "colab_type": "text"
      },
      "source": [
        "## Simple Tensor Operations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rv4jjqBVdIB2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "a54f5bcd-077f-4ca7-b501-3600f4ffafce"
      },
      "source": [
        "x = torch.ones([3, 2])\n",
        "y = torch.ones([3, 2])\n",
        "z = x + y\n",
        "print(z)\n",
        "z = x - y\n",
        "print(z)\n",
        "z = x * y\n",
        "print(z)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[2., 2.],\n",
            "        [2., 2.],\n",
            "        [2., 2.]])\n",
            "tensor([[0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 0.]])\n",
            "tensor([[1., 1.],\n",
            "        [1., 1.],\n",
            "        [1., 1.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dVHnXB78dl8s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "33e745c4-c496-4115-a22f-bbc60192268c"
      },
      "source": [
        "z = y.add(x)\n",
        "print(z)\n",
        "print(y)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[2., 2.],\n",
            "        [2., 2.],\n",
            "        [2., 2.]])\n",
            "tensor([[1., 1.],\n",
            "        [1., 1.],\n",
            "        [1., 1.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LewBBuz_eL1m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "a45995a1-6b7a-4303-8703-29aa96a9ea19"
      },
      "source": [
        "z = y.add_(x)\n",
        "print(z)\n",
        "print(y)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[2., 2.],\n",
            "        [2., 2.],\n",
            "        [2., 2.]])\n",
            "tensor([[2., 2.],\n",
            "        [2., 2.],\n",
            "        [2., 2.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PDuBSdzTc2Bq",
        "colab_type": "text"
      },
      "source": [
        "## Numpy <> PyTorch (Bridge or interface of numpy and pytorch)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NlvqO8_1ccML",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "5b3d57c6-d70f-4d40-c884-83075fcb84ab"
      },
      "source": [
        "x_np = x.numpy() # converting torch tensor to numpy nd array\n",
        "print(type(x), type(x_np))\n",
        "print(x_np)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'torch.Tensor'> <class 'numpy.ndarray'>\n",
            "[[1. 1.]\n",
            " [1. 1.]\n",
            " [1. 1.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tLhS3Hrmc-M2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "0d7a5872-c1ae-45d3-99fa-8a3508321fdc"
      },
      "source": [
        "a = np.random.randn(5)\n",
        "print(a)\n",
        "a_pt = torch.from_numpy(a) # converting numpy nd array to torch tensor\n",
        "print(type(a), type(a_pt))\n",
        "print(a_pt)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[-0.59056676 -0.21885342 -2.13425143  0.78068824  1.25396419]\n",
            "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n",
            "tensor([-0.5906, -0.2189, -2.1343,  0.7807,  1.2540], dtype=torch.float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kwZhRYVtdp-X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "043e9fa3-ea2a-417a-bcfb-8b24921c6d56"
      },
      "source": [
        " np.add(a, 1, out=a) # pointwise addition of 1 to all elements of a\n",
        "''' Both a and a_pt are updated. This means they are not a copy but refers the\n",
        "same numerical store and operates at the corresponding data structure\n",
        "\n",
        "i.e., memory_1 <- numpy operation (data structure)\n",
        "and   memory_1 <- pytorch operation (data structure)'''\n",
        "\n",
        "print(a)\n",
        "print(a_pt)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 0.40943324  0.78114658 -1.13425143  1.78068824  2.25396419]\n",
            "tensor([ 0.4094,  0.7811, -1.1343,  1.7807,  2.2540], dtype=torch.float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6z-Mhf2hewcU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "1a9d3346-cddc-4ac9-de12-e3e9434d6177"
      },
      "source": [
        "%%time\n",
        "for i in range(100):\n",
        "  a = np.random.randn(100,100)\n",
        "  b = np.random.randn(100,100)\n",
        "  c = np.matmul(a, b)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 151 ms, sys: 100 ms, total: 251 ms\n",
            "Wall time: 133 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aFzIX2qge3x9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "2269fde1-bc42-4fed-f1a3-a355190c8704"
      },
      "source": [
        "%%time\n",
        "for i in range(100):\n",
        "  a = torch.randn([100, 100])\n",
        "  b = torch.randn([100, 100])\n",
        "  c = torch.matmul(a, b)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 55.8 ms, sys: 77.9 ms, total: 134 ms\n",
            "Wall time: 107 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pdat0Hnm6hGA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "02bee6b4-cc8a-461d-b575-2206aac35d2b"
      },
      "source": [
        "%%time\n",
        "for i in range(10):\n",
        "  a = np.random.randn(10000,10000)\n",
        "  b = np.random.randn(10000,10000)\n",
        "  c = a + b"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 1min 27s, sys: 736 ms, total: 1min 27s\n",
            "Wall time: 1min 27s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XlRx5OKl6kEq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "5693c394-6caa-4b8a-addd-acf469be56ef"
      },
      "source": [
        "%%time\n",
        "for i in range(10):\n",
        "  a = torch.randn([10000, 10000])\n",
        "  b = torch.randn([10000, 10000])\n",
        "  c = a + b"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 25.6 s, sys: 7.94 ms, total: 25.6 s\n",
            "Wall time: 25.6 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "de5YwtfUgMWO",
        "colab_type": "text"
      },
      "source": [
        "## CUDA support"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-nI4nYcWgY1B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "65cce0c6-0ff3-45f1-b0aa-4c911e7891f2"
      },
      "source": [
        "# to identify whether there are any GPU available in the system\n",
        "# # CUDA supported devices\n",
        "# CUDA - language extension by NVIDIA to support programming GPU's directly\n",
        "print(torch.cuda.device_count())"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_3E-PMC1gfKU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "d9902fd4-313e-4ce5-f7f3-167af5eef172"
      },
      "source": [
        "print(torch.cuda.device(0)) # reference to object within torch\n",
        "print(torch.cuda.get_device_name(0)) # kind of device"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<torch.cuda.device object at 0x7fea7f2bf2b0>\n",
            "Tesla P100-PCIE-16GB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_eZYxVpMgor4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# GPU device \"Tesla P100-PCIE-16GB\" at location 0\n",
        "cuda0 = torch.device('cuda:0') # reference variable of the GPU device"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j1r7y57x9JZU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "8af8207f-4c95-474e-d977-e1edf2572583"
      },
      "source": [
        "a = torch.ones(3, 2, device=cuda0) # tensor created on GPU\n",
        "b = torch.ones(3, 2, device=cuda0) # tensor created on GPU\n",
        "c = a + b\n",
        "print(c)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[2., 2.],\n",
            "        [2., 2.],\n",
            "        [2., 2.]], device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wSt3W1s-_Gc3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "b1c221be-6d05-4252-fc52-39083adf3b02"
      },
      "source": [
        "print(a)\n",
        "print(b)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1., 1.],\n",
            "        [1., 1.],\n",
            "        [1., 1.]], device='cuda:0')\n",
            "tensor([[1., 1.],\n",
            "        [1., 1.],\n",
            "        [1., 1.]], device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sVfOAU2EfTXB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "98116785-c923-4a67-abed-5e0fcc7eadeb"
      },
      "source": [
        "''' NumPy operation on CPU '''\n",
        "%%time\n",
        "for i in range(10):\n",
        "  a = np.random.randn(10000,10000)\n",
        "  b = np.random.randn(10000,10000)\n",
        "  np.add(b, a)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 1min 28s, sys: 345 ms, total: 1min 28s\n",
            "Wall time: 1min 28s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G9GLUek5hCfn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "8192d37a-fccd-442c-ec2b-93fc58cf7217"
      },
      "source": [
        "''' PyTorch operation on CPU '''\n",
        "%%time\n",
        "for i in range(10):\n",
        "  a_cpu = torch.randn([10000, 10000])\n",
        "  b_cpu = torch.randn([10000, 10000])\n",
        "  b_cpu.add_(a_cpu)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 25.6 s, sys: 16.9 ms, total: 25.6 s\n",
            "Wall time: 25.6 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FqSYioGrgyMI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "38d60bf9-3bc1-4d5d-e858-26daff8c0df2"
      },
      "source": [
        "''' PyTorch operation on GPU '''\n",
        "%%time\n",
        "for i in range(10):\n",
        "  a = torch.randn([10000, 10000], device=cuda0)\n",
        "  b = torch.randn([10000, 10000], device=cuda0)\n",
        "  b.add_(a)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 1.82 ms, sys: 1.99 ms, total: 3.81 ms\n",
            "Wall time: 13.3 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kjsl8xRFjPtT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "63f64490-b383-4cec-ec5d-ced9a2e78330"
      },
      "source": [
        "%%time\n",
        "for i in range(10):\n",
        "  a = np.random.randn(10000,10000)\n",
        "  b = np.random.randn(10000,10000)\n",
        "  np.matmul(b, a)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 20min 32s, sys: 5.78 s, total: 20min 38s\n",
            "Wall time: 11min 15s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "avFqbCgXjT3F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "7a85625c-7374-403c-ae92-6d5f1af80e8c"
      },
      "source": [
        "%%time\n",
        "for i in range(10):\n",
        "  a_cpu = torch.randn([10000, 10000])\n",
        "  b_cpu = torch.randn([10000, 10000])\n",
        "  torch.matmul(a_cpu, b_cpu)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 5min 1s, sys: 236 ms, total: 5min 1s\n",
            "Wall time: 5min 1s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFfMhN2gjlZJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "70b09af4-aa2a-49db-c06e-b92d6fd78a62"
      },
      "source": [
        "%%time\n",
        "for i in range(10):\n",
        "  a = torch.randn([10000, 10000], device=cuda0)\n",
        "  b = torch.randn([10000, 10000], device=cuda0)\n",
        "  torch.matmul(a, b)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 4.14 ms, sys: 2.99 ms, total: 7.13 ms\n",
            "Wall time: 7.56 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P_6TU64Gi7jv",
        "colab_type": "text"
      },
      "source": [
        "## Autodiff (Tensor: 1. On data structure level it is about storing the multidimensional matrices, 2. On structural level it relates different tensors with each other)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PjySsLMThEX7",
        "colab_type": "code",
        "outputId": "799d9a12-e2d1-433a-a142-ab1817e97553",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# requires_grad = True tells pytorch that a particular is going to be \n",
        "# differentiable based on some function\n",
        "# i.e., if x is a tensor and set as differentiable then y is a tensor or some function\n",
        "# which differentiates with respect to x (this is because different tensors relate with\n",
        "# each other. Say in the below case we can see that y = x + 5 is a simple linear relation).\n",
        "x = torch.ones([3, 2], requires_grad=True)\n",
        "print(x)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1., 1.],\n",
            "        [1., 1.],\n",
            "        [1., 1.]], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "neb3oFWBjAtJ",
        "colab_type": "code",
        "outputId": "702b1c6f-736f-47bb-ae5a-7f9da816e9dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# The power of Tensor can be seen just by the ability of modeling the relations\n",
        "# between different high dimensional matrices (tensors) is what makes tensors to\n",
        "# stand apart. \n",
        "\n",
        "y = x + 5\n",
        "print(y)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[6., 6.],\n",
            "        [6., 6.],\n",
            "        [6., 6.]], grad_fn=<AddBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5M0pnstAjLa-",
        "colab_type": "code",
        "outputId": "87b98319-cd7d-42ba-e1ae-e644acb0f2cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "z = y*y + 1\n",
        "print(z)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[37., 37.],\n",
            "        [37., 37.],\n",
            "        [37., 37.]], grad_fn=<AddBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wHHDSmiUkMOw",
        "colab_type": "code",
        "outputId": "f5b8e8c3-324d-4f55-fbd2-99adf931792d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "t = torch.sum(z)\n",
        "print(t)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(222., grad_fn=<SumBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AXj896azkM_S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "t.backward() # backward propogation starting from t"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wSYAcNN1lAWS",
        "colab_type": "code",
        "outputId": "d8c494d3-1c37-48bc-e3c8-79159c00d215",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "print(x.grad) # differentiation of t with respect to x (.grad is just call for derivative operation)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[12., 12.],\n",
            "        [12., 12.],\n",
            "        [12., 12.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6nrD44oJiEIY",
        "colab_type": "text"
      },
      "source": [
        "$t = \\sum_i z_i, z_i = y_i^2 + 1, y_i = x_i + 5$\n",
        "\n",
        "$\\frac{\\partial t}{\\partial x_i} = \\frac{\\partial z_i}{\\partial x_i} = \\frac{\\partial z_i}{\\partial y_i} \\frac{\\partial y_i}{\\partial x_i} = 2y_i \\times 1$\n",
        "\n",
        "\n",
        "At x = 1, y = 6, $\\frac{\\partial t}{\\partial x_i} = 12$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZFCWPPAP6ipv",
        "colab_type": "code",
        "outputId": "659c6a43-9fd1-4a97-92bb-1400c801bbb4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "x = torch.ones([3, 2], requires_grad=True)\n",
        "y = x + 5\n",
        "r = 1/(1 + torch.exp(-y))\n",
        "print(r)\n",
        "s = torch.sum(r)\n",
        "s.backward()\n",
        "print(x.grad)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.9975, 0.9975],\n",
            "        [0.9975, 0.9975],\n",
            "        [0.9975, 0.9975]], grad_fn=<MulBackward0>)\n",
            "tensor([[0.0025, 0.0025],\n",
            "        [0.0025, 0.0025],\n",
            "        [0.0025, 0.0025]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ts1wsONqlE5h",
        "colab_type": "code",
        "outputId": "c30c29aa-e64e-4450-ff6e-af7fe1f39731",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "x = torch.ones([3, 2], requires_grad=True)\n",
        "y = x + 5\n",
        "r = 1/(1 + torch.exp(-y))\n",
        "a = torch.ones([3, 2])\n",
        "r.backward(a)\n",
        "print(x.grad)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.0025, 0.0025],\n",
            "        [0.0025, 0.0025],\n",
            "        [0.0025, 0.0025]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "56AqY5hY77dx",
        "colab_type": "text"
      },
      "source": [
        "$\\frac{\\partial{s}}{\\partial{x}} = \\frac{\\partial{s}}{\\partial{r}} \\cdot \\frac{\\partial{r}}{\\partial{x}}$\n",
        "\n",
        "For the above code $a$ represents $\\frac{\\partial{s}}{\\partial{r}}$ and then $x.grad$ gives directly $\\frac{\\partial{s}}{\\partial{x}}$\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AKhxwdYUpUfj",
        "colab_type": "text"
      },
      "source": [
        "## Autodiff example that looks like what we have been doing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "THNkQLR6mmpO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        },
        "outputId": "94c792b5-148e-4898-ff9c-76e21e5c98d2"
      },
      "source": [
        "# True function\n",
        "x = torch.randn([20, 1], requires_grad=True) # 20 data items or rows which are the input feature \n",
        "# We know the real values of w as +3 and b as -2\n",
        "y = 3*x - 2 # ground truth model which is the corresponding true output of x\n",
        "print(x)\n",
        "print(y)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-0.7942],\n",
            "        [-2.8174],\n",
            "        [ 1.3101],\n",
            "        [-0.9173],\n",
            "        [ 0.3928],\n",
            "        [-0.3163],\n",
            "        [-0.4522],\n",
            "        [-0.5039],\n",
            "        [ 1.5010],\n",
            "        [-1.0879],\n",
            "        [-0.2494],\n",
            "        [-0.0527],\n",
            "        [-0.7158],\n",
            "        [ 0.5733],\n",
            "        [-1.7799],\n",
            "        [-0.4007],\n",
            "        [-1.4680],\n",
            "        [ 1.2438],\n",
            "        [ 1.1957],\n",
            "        [-1.2975]], requires_grad=True)\n",
            "tensor([[ -4.3825],\n",
            "        [-10.4523],\n",
            "        [  1.9302],\n",
            "        [ -4.7519],\n",
            "        [ -0.8215],\n",
            "        [ -2.9490],\n",
            "        [ -3.3567],\n",
            "        [ -3.5117],\n",
            "        [  2.5031],\n",
            "        [ -5.2636],\n",
            "        [ -2.7483],\n",
            "        [ -2.1580],\n",
            "        [ -4.1475],\n",
            "        [ -0.2801],\n",
            "        [ -7.3396],\n",
            "        [ -3.2021],\n",
            "        [ -6.4040],\n",
            "        [  1.7314],\n",
            "        [  1.5871],\n",
            "        [ -5.8926]], grad_fn=<SubBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-t4_8qgdnjDk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "9dfae8cb-74c9-43e1-b0b3-c7edad195e08"
      },
      "source": [
        "# Hypothesis function (Forward pass)\n",
        "# Initially we estimate the values of w and b as 1 and 1\n",
        "w = torch.tensor([1.], requires_grad=True)\n",
        "b = torch.tensor([1.], requires_grad=True)\n",
        "\n",
        "y_hat = w*x + b # hypothesis function for prediction\n",
        "\n",
        "loss = torch.sum((y_hat - y)**2) # square error loss\n",
        "\n",
        "print(y_hat)\n",
        "print(loss)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 0.2058],\n",
            "        [-1.8174],\n",
            "        [ 2.3101],\n",
            "        [ 0.0827],\n",
            "        [ 1.3928],\n",
            "        [ 0.6837],\n",
            "        [ 0.5478],\n",
            "        [ 0.4961],\n",
            "        [ 2.5010],\n",
            "        [-0.0879],\n",
            "        [ 0.7506],\n",
            "        [ 0.9473],\n",
            "        [ 0.2842],\n",
            "        [ 1.5733],\n",
            "        [-0.7799],\n",
            "        [ 0.5993],\n",
            "        [-0.4680],\n",
            "        [ 2.2438],\n",
            "        [ 2.1957],\n",
            "        [-0.2975]], grad_fn=<AddBackward0>)\n",
            "tensor(364.9410, grad_fn=<SumBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gvpc37u-o6ob",
        "colab_type": "code",
        "outputId": "afcf8d06-aac4-4600-8cb4-c7878da8d328",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(loss)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(364.9410, grad_fn=<SumBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-tnKq6DXo-RB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Backward pass\n",
        "loss.backward()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I38qmZLhpM2F",
        "colab_type": "code",
        "outputId": "315eea12-9b01-4f8b-b753-888bee4d3c62",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# w.grad is the derivative of loss w.r.t to w\n",
        "# b.grad is the derivative of loss w.r.t to b\n",
        "print(w.grad, b.grad)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([-114.4924]) tensor([123.6175])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WfDV6saTq8XA",
        "colab_type": "text"
      },
      "source": [
        "## Do it in a loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ivmJgJQTpN79",
        "colab_type": "code",
        "outputId": "831ec258-0f1e-4dbb-843f-d413a54c0784",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 227
        }
      },
      "source": [
        "# learning algorithm to find out the right values of w and b\n",
        "\n",
        "learning_rate = 0.01\n",
        "\n",
        "w = torch.tensor([1.], requires_grad=True)\n",
        "b = torch.tensor([1.], requires_grad=True)\n",
        "\n",
        "print(w.item(), b.item())\n",
        "\n",
        "for i in range(10): # think this as epochs\n",
        "  \n",
        "  x = torch.randn([20, 1])\n",
        "  y = 3*x - 2\n",
        "  \n",
        "  y_hat = w*x + b\n",
        "  loss = torch.sum((y_hat - y)**2)\n",
        "  \n",
        "  loss.backward()\n",
        "  \n",
        "  with torch.no_grad(): # to prevent further computation graph (forward pass) build up (no more backpropogation)\n",
        "    w -= learning_rate * w.grad\n",
        "    b -= learning_rate * b.grad\n",
        "    \n",
        "    w.grad.zero_()\n",
        "    b.grad.zero_()\n",
        "\n",
        "  print(w.item(), b.item())\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.0 1.0\n",
            "1.694516658782959 -0.32816600799560547\n",
            "2.5244972705841064 -0.9011859893798828\n",
            "2.6990771293640137 -1.3381099700927734\n",
            "2.7810328006744385 -1.5905817747116089\n",
            "2.821857213973999 -1.7378290891647339\n",
            "2.943121910095215 -1.868725061416626\n",
            "2.9525837898254395 -1.9191371202468872\n",
            "2.9741718769073486 -1.9551563262939453\n",
            "2.9911296367645264 -1.972025752067566\n",
            "2.994936943054199 -1.9838125705718994\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vyOqrZZiuLkl",
        "colab_type": "text"
      },
      "source": [
        "## Do it for a large problem"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qq3Iykk1rMfh",
        "colab_type": "code",
        "outputId": "eb796c92-c327-4414-b77a-f6d6a72296c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "%%time\n",
        "# PyTorch operation on CPU\n",
        "learning_rate = 0.001\n",
        "N = 1000000\n",
        "epochs = 200\n",
        "\n",
        "w = torch.rand([N], requires_grad=True)\n",
        "b = torch.ones([1], requires_grad=True)\n",
        "\n",
        "#print(torch.mean(w).item(), b.item())\n",
        "\n",
        "for i in range(epochs):\n",
        "  \n",
        "  x = torch.randn([N])\n",
        "  y = torch.dot(3*torch.ones([N]), x) - 2\n",
        "  \n",
        "  y_hat = torch.dot(w, x) + b\n",
        "  loss = torch.sum((y_hat - y)**2)\n",
        "  \n",
        "  loss.backward()\n",
        "  \n",
        "  with torch.no_grad():\n",
        "    w -= learning_rate * w.grad\n",
        "    b -= learning_rate * b.grad\n",
        "    \n",
        "    w.grad.zero_()\n",
        "    b.grad.zero_()\n",
        "\n",
        "#  print(torch.mean(w).item(), b.item())\n",
        "print(x)  "
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([ 1.8770,  0.9379, -0.7311,  ..., -0.2719,  0.3658, -0.7566])\n",
            "CPU times: user 3.26 s, sys: 48.9 ms, total: 3.31 s\n",
            "Wall time: 3.32 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "owaeEn4A01zF",
        "colab_type": "code",
        "outputId": "8aef3854-ee0a-48f3-f419-5f4b16d5bcc4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%%time\n",
        "# PyTorch operation on GPU\n",
        "learning_rate = 0.001\n",
        "N = 444444444\n",
        "epochs = 200\n",
        "\n",
        "w = torch.rand([N], requires_grad=True, device=cuda0)\n",
        "b = torch.ones([1], requires_grad=True, device=cuda0)\n",
        "\n",
        "# print(torch.mean(w).item(), b.item())\n",
        "\n",
        "for i in range(epochs):\n",
        "  \n",
        "  x = torch.randn([N], device=cuda0)\n",
        "  y = torch.dot(3*torch.ones([N], device=cuda0), x) - 2\n",
        "  \n",
        "  y_hat = torch.dot(w, x) + b\n",
        "  loss = torch.sum((y_hat - y)**2)\n",
        "  \n",
        "  loss.backward()\n",
        "  \n",
        "  with torch.no_grad():\n",
        "    w -= learning_rate * w.grad\n",
        "    b -= learning_rate * b.grad\n",
        "    \n",
        "    w.grad.zero_()\n",
        "    b.grad.zero_()\n",
        "\n",
        "  #print(torch.mean(w).item(), b.item())"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 7.88 s, sys: 5.38 s, total: 13.3 s\n",
            "Wall time: 13.3 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hi7euV2K4K6e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Speed comparison: NumPy < PyTorch < PyTorch on GPU"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}