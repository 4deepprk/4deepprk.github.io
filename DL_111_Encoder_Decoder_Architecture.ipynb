{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL 111 - Encoder Decoder Architecture.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/4deepprk/4deepprk.github.io/blob/master/DL_111_Encoder_Decoder_Architecture.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IOI4rlrgxPI-",
        "colab_type": "text"
      },
      "source": [
        "## Outline\n",
        "\n",
        "\n",
        "1. Data set and task\n",
        "2. Data processing XML files\n",
        "3. Why we need encoder decoder architecture\n",
        "4. Basic GRU based encoder decoder\n",
        "5. Adding attention\n",
        "6. Evaluation\n",
        "7. Exercises"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1GqTjeV47m4B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "2132bfd7-c94c-4c36-e0f4-33f2d0b37963"
      },
      "source": [
        "# Machine Transliteration\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "\n",
        "# Instantiates the device to be used as GPU/CPU based on availability\n",
        "device_gpu = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Visualization tools\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from IPython.display import clear_output\n",
        "\n",
        "import random"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KpuvHS0mxwCd",
        "colab_type": "text"
      },
      "source": [
        "## Data Management"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eYrAa5laSptM",
        "colab_type": "text"
      },
      "source": [
        "### Alphabets Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-a04ZKx7Sh-J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "f740dbef-bc5e-4b85-a8cc-b3a9176d472c"
      },
      "source": [
        "# numerical representation of alphabets and pad\n",
        "# (can be used to write one hot encoded representation for each character and\n",
        "# also for each word in the dataset)\n",
        "\n",
        "eng_alphabets = 'ABCDEFGHIJKLMNOPQRSTUVWXYZ' # 26 characters\n",
        "pad_char = '-PAD-'\n",
        "\n",
        "eng_alpha2index = {pad_char: 0}\n",
        "for index, alpha in enumerate(eng_alphabets):\n",
        "    eng_alpha2index[alpha] = index+1\n",
        "\n",
        "print(eng_alpha2index) "
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'-PAD-': 0, 'A': 1, 'B': 2, 'C': 3, 'D': 4, 'E': 5, 'F': 6, 'G': 7, 'H': 8, 'I': 9, 'J': 10, 'K': 11, 'L': 12, 'M': 13, 'N': 14, 'O': 15, 'P': 16, 'Q': 17, 'R': 18, 'S': 19, 'T': 20, 'U': 21, 'V': 22, 'W': 23, 'X': 24, 'Y': 25, 'Z': 26}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPSZsy1kXd9w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "2ec1adbd-f319-49b4-c582-58a033750a8d"
      },
      "source": [
        "# Hindi Unicode Hex Range is 2304:2432. Source: https://en.wikipedia.org/wiki/Devanagari_(Unicode_block)\n",
        "# 128 varnamala (2304-2432) characters\n",
        "hindi_alphabets = [chr(alpha) for alpha in range(2304, 2432)]\n",
        "hindi_alphabet_size = len(hindi_alphabets)\n",
        "\n",
        "hindi_alpha2index = {pad_char: 0}\n",
        "for index, alpha in enumerate(hindi_alphabets):\n",
        "    hindi_alpha2index[alpha] = index+1\n",
        "\n",
        "print(hindi_alpha2index)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'-PAD-': 0, 'ऀ': 1, 'ँ': 2, 'ं': 3, 'ः': 4, 'ऄ': 5, 'अ': 6, 'आ': 7, 'इ': 8, 'ई': 9, 'उ': 10, 'ऊ': 11, 'ऋ': 12, 'ऌ': 13, 'ऍ': 14, 'ऎ': 15, 'ए': 16, 'ऐ': 17, 'ऑ': 18, 'ऒ': 19, 'ओ': 20, 'औ': 21, 'क': 22, 'ख': 23, 'ग': 24, 'घ': 25, 'ङ': 26, 'च': 27, 'छ': 28, 'ज': 29, 'झ': 30, 'ञ': 31, 'ट': 32, 'ठ': 33, 'ड': 34, 'ढ': 35, 'ण': 36, 'त': 37, 'थ': 38, 'द': 39, 'ध': 40, 'न': 41, 'ऩ': 42, 'प': 43, 'फ': 44, 'ब': 45, 'भ': 46, 'म': 47, 'य': 48, 'र': 49, 'ऱ': 50, 'ल': 51, 'ळ': 52, 'ऴ': 53, 'व': 54, 'श': 55, 'ष': 56, 'स': 57, 'ह': 58, 'ऺ': 59, 'ऻ': 60, '़': 61, 'ऽ': 62, 'ा': 63, 'ि': 64, 'ी': 65, 'ु': 66, 'ू': 67, 'ृ': 68, 'ॄ': 69, 'ॅ': 70, 'ॆ': 71, 'े': 72, 'ै': 73, 'ॉ': 74, 'ॊ': 75, 'ो': 76, 'ौ': 77, '्': 78, 'ॎ': 79, 'ॏ': 80, 'ॐ': 81, '॑': 82, '॒': 83, '॓': 84, '॔': 85, 'ॕ': 86, 'ॖ': 87, 'ॗ': 88, 'क़': 89, 'ख़': 90, 'ग़': 91, 'ज़': 92, 'ड़': 93, 'ढ़': 94, 'फ़': 95, 'य़': 96, 'ॠ': 97, 'ॡ': 98, 'ॢ': 99, 'ॣ': 100, '।': 101, '॥': 102, '०': 103, '१': 104, '२': 105, '३': 106, '४': 107, '५': 108, '६': 109, '७': 110, '८': 111, '९': 112, '॰': 113, 'ॱ': 114, 'ॲ': 115, 'ॳ': 116, 'ॴ': 117, 'ॵ': 118, 'ॶ': 119, 'ॷ': 120, 'ॸ': 121, 'ॹ': 122, 'ॺ': 123, 'ॻ': 124, 'ॼ': 125, 'ॽ': 126, 'ॾ': 127, 'ॿ': 128}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSw1SMZmx9A3",
        "colab_type": "text"
      },
      "source": [
        "### Helper functions for data pre-processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OcS6ByndOxrC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re # regular expression (for string processing)\n",
        "\n",
        "non_eng_letters_regex = re.compile('[^a-zA-Z ]') # looks for all letters which \n",
        "                                                 # are neither small a to z, A \n",
        "                                                 # to Z, and space   \n",
        "\n",
        "# Remove all English non-letters\n",
        "# Function ensures that every character is a key in the respective dictionaries\n",
        "# (english)\n",
        "def cleanEnglishVocab(line):\n",
        "    line = line.replace('-', ' ').replace(',', ' ').upper()\n",
        "    line = non_eng_letters_regex.sub('', line)\n",
        "    return line.split()\n",
        "\n",
        "# Remove all Hindi non-letters\n",
        "# Function ensures that every character is a key in the respective dictionaries\n",
        "# (hindi)\n",
        "def cleanHindiVocab(line):\n",
        "    line = line.replace('-', ' ').replace(',', ' ')\n",
        "    cleaned_line = ''\n",
        "    for char in line:\n",
        "        if char in hindi_alpha2index or char == ' ':\n",
        "            cleaned_line += char\n",
        "    return cleaned_line.split()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ob3F9Dh4PChB",
        "colab_type": "text"
      },
      "source": [
        "### Dataset Loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGSeoMGg0FTy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import Dataset # importing dataset from torch\n",
        "import xml.etree.ElementTree as ET # xml module for reading xml files\n",
        "\n",
        "# Using the dataset and trying to exploit its features for our problem\n",
        "class TransliterationDataLoader(Dataset): # class that extends dataset (torch)\n",
        "                                          # (it has common features like length, getitem, etc..)      \n",
        "    def __init__(self, filename):\n",
        "        # read XML files and extract english and hindi words lists  \n",
        "        self.eng_words, self.hindi_words = self.readXmlDataset(filename, cleanHindiVocab)\n",
        "        self.shuffle_indices = list(range(len(self.eng_words))) # shuffling the dataset (training in each batch \n",
        "                                                                # should look different in order to not get fixed in local minima)\n",
        "        random.shuffle(self.shuffle_indices)\n",
        "        self.shuffle_start_index = 0 # shuffles the data in a batch and starts from index 0 by setting the shuffle start index to 0\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.eng_words)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        return self.eng_words[idx], self.hindi_words[idx]\n",
        "    \n",
        "    def readXmlDataset(self, filename, lang_vocab_cleaner):\n",
        "        # parses the XML file and gets the root of the XML tree  \n",
        "        transliterationCorpus = ET.parse(filename).getroot() # (TransliterationCorpus tag is the root of the XML)\n",
        "        lang1_words = []\n",
        "        lang2_words = []\n",
        "\n",
        "        for line in transliterationCorpus: # iteratable nodes (childs of the root) or name tag\n",
        "            wordlist1 = cleanEnglishVocab(line[0].text) # (english text or gets text in source name tag)\n",
        "            wordlist2 = lang_vocab_cleaner(line[1].text) # (hindi text or gets text in target name tag)\n",
        "\n",
        "            # Skip noisy data\n",
        "            if len(wordlist1) != len(wordlist2):\n",
        "                print('Skipping: ', line[0].text, ' - ', line[1].text)\n",
        "                continue\n",
        "\n",
        "            for word in wordlist1:\n",
        "                lang1_words.append(word)\n",
        "            for word in wordlist2:\n",
        "                lang2_words.append(word)\n",
        "\n",
        "        return lang1_words, lang2_words # two lists containing cleaned english and hindi words\n",
        "    \n",
        "    def get_random_sample(self):\n",
        "        return self.__getitem__(np.random.randint(len(self.eng_words)))\n",
        "    \n",
        "    def get_batch_from_array(self, batch_size, array):\n",
        "        end = self.shuffle_start_index + batch_size\n",
        "        batch = []\n",
        "        if end >= len(self.eng_words):\n",
        "            batch = [array[i] for i in self.shuffle_indices[0:end%len(self.eng_words)]]\n",
        "            end = len(self.eng_words)\n",
        "        return batch + [array[i] for i in self.shuffle_indices[self.shuffle_start_index : end]]\n",
        "    \n",
        "    def get_batch(self, batch_size, postprocess = True):\n",
        "        eng_batch = self.get_batch_from_array(batch_size, self.eng_words)\n",
        "        hindi_batch = self.get_batch_from_array(batch_size, self.hindi_words)\n",
        "        self.shuffle_start_index += batch_size + 1\n",
        "        \n",
        "        # Reshuffle if 1 epoch is complete\n",
        "        if self.shuffle_start_index >= len(self.eng_words):\n",
        "            random.shuffle(self.shuffle_indices)\n",
        "            self.shuffle_start_index = 0\n",
        "            \n",
        "        return eng_batch, hindi_batch"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-FCCi-SerZS-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        },
        "outputId": "412907fe-e874-4349-af69-bb7519500ffd"
      },
      "source": [
        "train_data = TransliterationDataLoader('NEWS2012-Training-EnHi-13937.xml')\n",
        "test_data = TransliterationDataLoader('NEWS2012-Ref-EnHi-1000.xml')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Skipping:  BARHARWA JUNCTION  -  बरहरवा\n",
            "Skipping:  STATE BNK TR  -  स्टेट बैंक ऑफ त्रावणकोर\n",
            "Skipping:  SOUTH ARLINGTON CHURCH OF CHRIST  -  साउथ अर्लिंग्टन\n",
            "Skipping:  KING EDWARD VII  -  किंग एडवर्ड\n",
            "Skipping:  DIBANG VALLEY  -  दिबंगवैली\n",
            "Skipping:  ORDER OF VASA  -  ऑडर ऑफ़ द वासा\n",
            "Skipping:  AZAMNAGAR ROAD  -  आज़मनगर\n",
            "Skipping:  CAPE TOWN  -  केपटाउन\n",
            "Skipping:  NEW ZEALAND  -  न्यूज़ीलैंड\n",
            "Skipping:  SEA OF THE HEBRIDES  -  सी ऑफ हरब्रिड्‍स\n",
            "Skipping:  RAMCOIND  -  राम्को इंड\n",
            "Skipping:  KELVINGROVE ART GALLERY AND MUSEUM  -  केल्व‍िनग्रोव आर्ट एण्ड म्युज़ियम\n",
            "Skipping:  AUSTRALIAN NATIONAL UNIVERSITY  -  ऑस्ट्रेलियननेशनल यूनिवर्सिटी\n",
            "Skipping:  JAHAN AARA  -  जहाँआरा\n",
            "Skipping:  NAVABHARAT FERRO ALLOYS  -  नव भारत फ़ैरो अलॉय\n",
            "Skipping:  RAMA LINGESHWARA  -  रामालिंगेश्वर\n",
            "Skipping:  FAKHRUN NISA  -  फखरुन्निसा\n",
            "Skipping:  REDIFF.COM INDIA LIMITED  -  रेडिफ़ डॉट कॉम इंडिया लिमिटेड\n",
            "Skipping:  OMKARNATH THAKUR  -  ओंकार नाथ ठाकुर\n",
            "Skipping:  OPENTV  -  ओपन टीवी\n",
            "Skipping:  ENVOY COMMUNICATIONS GROUP  -  एन्वॉय कम्युनिकेशंस\n",
            "Skipping:  WAR OF THE HOLY LEAGUE  -  वार ऑफ होली लीग\n",
            "Skipping:  VAPARAISO CHURCH OF CHRIST  -  व्हापरासिओ\n",
            "Skipping:  PARIS CHARLES DE GAULLE  -  पेरिस रॉसे चार्ल्स डे ग्यूले\n",
            "Skipping:  PARKWAY APOSTOLIC  -  पार्क वे अपोस्टोलिक\n",
            "Skipping:  MAUNA LOA  -  मौनालोआ\n",
            "Skipping:  MASS MUTUAL LIFE  -  मास म्युच्युअल लाइफ़ इंश्योरेंस\n",
            "Skipping:  STATS CHIPPAC  -  स्टेट्सचिपपैक\n",
            "Skipping:  NEWFOUNDLAND  -  न्यू फाउंडलैंड\n",
            "Skipping:  LONDONHEATHROW  -  लंदन हीथ्रो\n",
            "Skipping:  RETALIX  -  रेटालिक्स लि.\n",
            "Skipping:  SRISAILAM  -  श्री शैलम\n",
            "Skipping:  KARA-KUM  -  काराकुम\n",
            "Skipping:  WIND RIVER  -  विंडरिवर\n",
            "Skipping:  NETAJI SUBHASH CHANDRA BOSE  -  नेताजी सुभाषचंद्र बोस\n",
            "Skipping:  ROCKBROOK UNITED  -  रॉकब्रुक यूनाइटेड मेथोडिस्ट\n",
            "Skipping:  WALTER SCOTT  -  वॉल्टरस्कॉट\n",
            "Skipping:  COLOURPLUS FASHIONS  -  कलर प्लस फ़ैशन्स\n",
            "Skipping:  BAL KRISHNA  -  बालकृष्णा\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7l-iaCVdx5Ez",
        "colab_type": "text"
      },
      "source": [
        "### Basic Data Visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IjY06ghEx76b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "d9fb519b-5a64-4939-f245-f7ca8a69f597"
      },
      "source": [
        "print(\"Train Set Size:\\t\", len(train_data))\n",
        "print(\"Test Set Size:\\t\", len(test_data))\n",
        "\n",
        "print('\\nSample data from train-set:')\n",
        "for i in range(10):\n",
        "    eng, hindi = train_data.get_random_sample()\n",
        "    print(eng + ' - ' + hindi)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Set Size:\t 20543\n",
            "Test Set Size:\t 1000\n",
            "\n",
            "Sample data from train-set:\n",
            "PRICKETTS - प्रिकेट्स\n",
            "PULISH - पुलिश\n",
            "AWAAM - आवाम\n",
            "BAALAAJEE - बालाजी\n",
            "PYAR - प्यार\n",
            "E - ए\n",
            "FORT - फोर्ट\n",
            "ONUYO - ओनूयो\n",
            "GWYN - ग्वायन\n",
            "AMALIE - एमेली\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KpDP1_KYZIkv",
        "colab_type": "text"
      },
      "source": [
        "### Encoding the words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JE3at5C7Sy5F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Encoding the input (English word) - 27 (26 alphabets + 1 padding)\n",
        "# Vectors of each character will be of size 27\n",
        "def word_rep(word, letter2index, device = 'cpu'):\n",
        "    rep = torch.zeros(len(word)+1, 1, len(letter2index)).to(device)\n",
        "    for letter_index, letter in enumerate(word):\n",
        "        pos = letter2index[letter]\n",
        "        rep[letter_index][0][pos] = 1\n",
        "    pad_pos = letter2index[pad_char]\n",
        "    rep[letter_index+1][0][pad_pos] = 1 # rep[#characters][dimension size of 1(batch)][#embedding size(27)]\n",
        "    return rep\n",
        "\n",
        "# Encoding the ground truth (Hindi word)\n",
        "def gt_rep(word, letter2index, device = 'cpu'):\n",
        "    gt_rep = torch.zeros([len(word)+1, 1], dtype=torch.long).to(device)\n",
        "    for letter_index, letter in enumerate(word):\n",
        "        pos = letter2index[letter]\n",
        "        gt_rep[letter_index][0] = pos\n",
        "    gt_rep[letter_index+1][0] = letter2index[pad_char]\n",
        "    return gt_rep"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-yE3jToOrfzP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "outputId": "709fe6c8-93b4-4a7b-fc37-ac8f7ea70a68"
      },
      "source": [
        "eng, hindi = train_data.get_random_sample()\n",
        "eng_rep = word_rep(eng, eng_alpha2index)\n",
        "print(eng, eng_rep) # (10, 1, 27) for PARSHURAM (10 charcter english input)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "KAISERIN tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uMcDjIberhc3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "7a6bd0fd-a49b-4aae-b0f5-c1dc39cdb160"
      },
      "source": [
        "hindi_gt = gt_rep(hindi, hindi_alpha2index)\n",
        "print(hindi, hindi_gt) # (8 characters in Hindi for PARSHURAM)\n",
        "\n",
        "# Input contains 10 character and ground truth contains 8 characters\n",
        "# Input should be encoded completely(encoder) such that the encoded inputs can \n",
        "# exactly map to the output part(decoder). 10 encoded characters in English \n",
        "# should be mapped or decoded on to 8 characters in Hindi (decode based on fully\n",
        "# encoded representation)."
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "कैसरीन tensor([[22],\n",
            "        [73],\n",
            "        [57],\n",
            "        [49],\n",
            "        [65],\n",
            "        [41],\n",
            "        [ 0]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GrC3tSnm4rUk",
        "colab_type": "text"
      },
      "source": [
        "## Network Architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D4OgdZ_DVVC5",
        "colab_type": "text"
      },
      "source": [
        "### Encoder-Decoder (using GRU)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6w8ffT3w4lkK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_OUTPUT_CHARS = 30\n",
        "class Transliteration_EncoderDecoder(nn.Module):\n",
        "    \n",
        "    def __init__(self, input_size, hidden_size, output_size, verbose=False):\n",
        "        super(Transliteration_EncoderDecoder, self).__init__()\n",
        "        \n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        \n",
        "        self.encoder_rnn_cell = nn.GRU(input_size, hidden_size)\n",
        "        # input to the decoder GRU is the same as the ouput of the precious cell\n",
        "        # and so the input is given as output_size  \n",
        "        self.decoder_rnn_cell = nn.GRU(output_size, hidden_size)\n",
        "        \n",
        "        self.h2o = nn.Linear(hidden_size, output_size)\n",
        "        self.softmax = nn.LogSoftmax(dim=2)\n",
        "        \n",
        "        self.verbose = verbose # verbose is useful to know the structure of architecture\n",
        "        # (remember to make verbose as False while training the model)\n",
        "        \n",
        "    def forward(self, input, max_output_chars = MAX_OUTPUT_CHARS, device = 'cpu', ground_truth = None):\n",
        "        \n",
        "        # encoder\n",
        "        out, hidden = self.encoder_rnn_cell(input)\n",
        "        \n",
        "        if self.verbose:\n",
        "            print('Encoder input', input.shape)\n",
        "            print('Encoder output', out.shape)\n",
        "            print('Encoder hidden', hidden.shape)\n",
        "        \n",
        "        # decoder\n",
        "        decoder_state = hidden\n",
        "        decoder_input = torch.zeros(1, 1, self.output_size).to(device)\n",
        "        outputs = []\n",
        "        \n",
        "        if self.verbose:\n",
        "            print('Decoder state', decoder_state.shape)\n",
        "            print('Decoder input', decoder_input.shape)\n",
        "        \n",
        "        for i in range(max_output_chars):\n",
        "            \n",
        "            out, decoder_state = self.decoder_rnn_cell(decoder_input, decoder_state)\n",
        "            \n",
        "            if self.verbose:\n",
        "                print('Decoder intermediate output', out.shape)\n",
        "            \n",
        "            out = self.h2o(decoder_state)\n",
        "            out = self.softmax(out)\n",
        "            outputs.append(out.view(1, -1))\n",
        "            \n",
        "            if self.verbose:\n",
        "                print('Decoder output', out.shape)\n",
        "                self.verbose = False\n",
        "            \n",
        "            max_idx = torch.argmax(out, 2, keepdim=True)\n",
        "            if not ground_truth is None:\n",
        "                max_idx = ground_truth[i].reshape(1, 1, 1)\n",
        "            one_hot = torch.FloatTensor(out.shape).to(device)\n",
        "            one_hot.zero_()\n",
        "            one_hot.scatter_(2, max_idx, 1)\n",
        "            \n",
        "            decoder_input = one_hot.detach()\n",
        "            \n",
        "        return outputs"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cra9toTiOoPm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net = Transliteration_EncoderDecoder(len(eng_alpha2index), 256, len(hindi_alpha2index), verbose=True)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yXkd5Dnic5KM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Infer\n",
        "def infer(net, word, max_op_chars):\n",
        "  out = net.forward(word_rep(word, eng_alpha2index), max_output_chars = max_op_chars)\n",
        "  return out"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v4zaJq2pOrM8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "out = infer(net, 'INDIA', 7)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_pdzBmQOsjO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "ceee8b2d-0ebb-48ee-fda8-8d17c5aae071"
      },
      "source": [
        "print(len(out))\n",
        "for i in range(len(out)):\n",
        "    print(out[i].shape, list(hindi_alpha2index.keys())[list(hindi_alpha2index.values()).index(torch.argmax(out[i]))])"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7\n",
            "torch.Size([1, 129]) ॅ\n",
            "torch.Size([1, 129]) ॼ\n",
            "torch.Size([1, 129]) ॼ\n",
            "torch.Size([1, 129]) ौ\n",
            "torch.Size([1, 129]) ॕ\n",
            "torch.Size([1, 129]) ॕ\n",
            "torch.Size([1, 129]) ऌ\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NEg49N9e7oTY",
        "colab_type": "text"
      },
      "source": [
        "### Encoder-Decoder with Attention \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8z-1QDAz8F_d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Transliteration_EncoderDecoder_Attention(nn.Module):\n",
        "    \n",
        "    def __init__(self, input_size, hidden_size, output_size, verbose=False):\n",
        "        super(Transliteration_EncoderDecoder_Attention, self).__init__()\n",
        "        \n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        \n",
        "        self.encoder_rnn_cell = nn.GRU(input_size, hidden_size)\n",
        "        self.decoder_rnn_cell = nn.GRU(hidden_size*2, hidden_size)\n",
        "        \n",
        "        self.h2o = nn.Linear(hidden_size, output_size)\n",
        "        self.softmax = nn.LogSoftmax(dim=2)\n",
        "        \n",
        "        self.U = nn.Linear(self.hidden_size, self.hidden_size)\n",
        "        self.W = nn.Linear(self.hidden_size, self.hidden_size)\n",
        "        self.attn = nn.Linear(self.hidden_size, 1)\n",
        "        self.out2hidden = nn.Linear(self.output_size, self.hidden_size)   \n",
        "        \n",
        "        self.verbose = verbose\n",
        "        \n",
        "    def forward(self, input, max_output_chars = MAX_OUTPUT_CHARS, device = 'cpu', ground_truth = None):\n",
        "        \n",
        "        # encoder\n",
        "        encoder_outputs, hidden = self.encoder_rnn_cell(input)\n",
        "        encoder_outputs = encoder_outputs.view(-1, self.hidden_size)\n",
        "        \n",
        "        if self.verbose:\n",
        "            print('Encoder output', encoder_outputs.shape)\n",
        "        \n",
        "        # decoder\n",
        "        decoder_state = hidden\n",
        "        decoder_input = torch.zeros(1, 1, self.output_size).to(device)\n",
        "        \n",
        "        outputs = []\n",
        "        U = self.U(encoder_outputs)\n",
        "        \n",
        "        if self.verbose:\n",
        "            print('Decoder state', decoder_state.shape)\n",
        "            print('Decoder intermediate input', decoder_input.shape)\n",
        "            print('U * Encoder output', U.shape)\n",
        "        \n",
        "        for i in range(max_output_chars):\n",
        "            \n",
        "            W = self.W(decoder_state.view(1, -1).repeat(encoder_outputs.shape[0], 1))\n",
        "            V = self.attn(torch.tanh(U + W))\n",
        "            attn_weights = F.softmax(V.view(1, -1), dim = 1) \n",
        "            \n",
        "            if self.verbose:\n",
        "                print('W * Decoder state', W.shape)\n",
        "                print('V', V.shape)\n",
        "                print('Attn', attn_weights.shape)\n",
        "            \n",
        "            attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
        "                                 encoder_outputs.unsqueeze(0))\n",
        "            \n",
        "            embedding = self.out2hidden(decoder_input)\n",
        "            decoder_input = torch.cat((embedding[0], attn_applied[0]), 1).unsqueeze(0)\n",
        "            \n",
        "            if self.verbose:\n",
        "                print('Attn LC', attn_applied.shape)\n",
        "                print('Decoder input', decoder_input.shape)\n",
        "                \n",
        "            out, decoder_state = self.decoder_rnn_cell(decoder_input, decoder_state)\n",
        "            \n",
        "            if self.verbose:\n",
        "                print('Decoder intermediate output', out.shape)\n",
        "                \n",
        "            out = self.h2o(decoder_state)\n",
        "            out = self.softmax(out)\n",
        "            outputs.append(out.view(1, -1))\n",
        "            \n",
        "            if self.verbose:\n",
        "                print('Decoder output', out.shape)\n",
        "                self.verbose = False\n",
        "            \n",
        "            max_idx = torch.argmax(out, 2, keepdim=True)\n",
        "            if not ground_truth is None:\n",
        "                max_idx = ground_truth[i].reshape(1, 1, 1)\n",
        "            one_hot = torch.zeros(out.shape, device=device)\n",
        "            one_hot.scatter_(2, max_idx, 1) \n",
        "            \n",
        "            decoder_input = one_hot.detach()\n",
        "            \n",
        "        return outputs"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PMD3zjdJO0Oj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net_attn = Transliteration_EncoderDecoder_Attention(len(eng_alpha2index), 256, len(hindi_alpha2index), verbose=True)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YoiQwbntO5UH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "19e14393-6f33-4d9f-8644-be6e884e987b"
      },
      "source": [
        "out = infer(net_attn, 'INDIA', 7)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Encoder output torch.Size([6, 256])\n",
            "Decoder state torch.Size([1, 1, 256])\n",
            "Decoder intermediate input torch.Size([1, 1, 129])\n",
            "U * Encoder output torch.Size([6, 256])\n",
            "W * Decoder state torch.Size([6, 256])\n",
            "V torch.Size([6, 1])\n",
            "Attn torch.Size([1, 6])\n",
            "Attn LC torch.Size([1, 1, 256])\n",
            "Decoder input torch.Size([1, 1, 512])\n",
            "Decoder intermediate output torch.Size([1, 1, 256])\n",
            "Decoder output torch.Size([1, 1, 129])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K9WSPgzlO6k8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "4f0d3feb-1c2a-4f52-8e00-73961261f65a"
      },
      "source": [
        "print(len(out))\n",
        "for i in range(len(out)):\n",
        "    print(out[i].shape, list(hindi_alpha2index.keys())[list(hindi_alpha2index.values()).index(torch.argmax(out[i]))])"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7\n",
            "torch.Size([1, 129]) ३\n",
            "torch.Size([1, 129]) ॐ\n",
            "torch.Size([1, 129]) ॐ\n",
            "torch.Size([1, 129]) घ\n",
            "torch.Size([1, 129]) ३\n",
            "torch.Size([1, 129]) ॐ\n",
            "torch.Size([1, 129]) घ\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cyE2tSnmAW6x",
        "colab_type": "text"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H893cimDtTUE",
        "colab_type": "text"
      },
      "source": [
        "### Core Trainer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m804jsH7AXSV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_batch(net, opt, criterion, batch_size, device = 'cpu', teacher_force = False):\n",
        "    \n",
        "    net.train().to(device)\n",
        "    opt.zero_grad()\n",
        "    eng_batch, hindi_batch = train_data.get_batch(batch_size)\n",
        "    \n",
        "    total_loss = 0\n",
        "    for i in range(batch_size):\n",
        "        \n",
        "        input = word_rep(eng_batch[i], eng_alpha2index, device)\n",
        "        gt = gt_rep(hindi_batch[i], hindi_alpha2index, device)\n",
        "        outputs = net(input, gt.shape[0], device, ground_truth = gt if teacher_force else None)\n",
        "        \n",
        "        for index, output in enumerate(outputs):\n",
        "            loss = criterion(output, gt[index]) / batch_size\n",
        "            loss.backward(retain_graph = True)\n",
        "            total_loss += loss\n",
        "        \n",
        "    opt.step()\n",
        "    return total_loss/batch_size"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p-eZaBxstWz9",
        "colab_type": "text"
      },
      "source": [
        "### Training Helper"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rjto129ssrpr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_setup(net, lr = 0.01, n_batches = 100, batch_size = 10, momentum = 0.9, display_freq=5, device = 'cpu'):\n",
        "    \n",
        "    net = net.to(device)\n",
        "    criterion = nn.NLLLoss(ignore_index = -1)\n",
        "    opt = optim.Adam(net.parameters(), lr=lr)\n",
        "    teacher_force_upto = n_batches//3\n",
        "    \n",
        "    loss_arr = np.zeros(n_batches + 1)\n",
        "    \n",
        "    for i in range(n_batches):\n",
        "        loss_arr[i+1] = (loss_arr[i]*i + train_batch(net, opt, criterion, batch_size, device = device, teacher_force = i<teacher_force_upto ))/(i + 1)\n",
        "        \n",
        "        if i%display_freq == display_freq-1:\n",
        "            clear_output(wait=True)\n",
        "            \n",
        "            print('Iteration', i, 'Loss', loss_arr[i])\n",
        "            plt.figure()\n",
        "            plt.plot(loss_arr[1:i], '-*')\n",
        "            plt.xlabel('Iteration')\n",
        "            plt.ylabel('Loss')\n",
        "            plt.show()\n",
        "            print('\\n\\n')\n",
        "            \n",
        "    torch.save(net, 'model.pt')\n",
        "    return loss_arr"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TZY6RvqLtdX8",
        "colab_type": "text"
      },
      "source": [
        "### Training without Attention"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1oQ3ZIWvtjfN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net = Transliteration_EncoderDecoder(len(eng_alpha2index), 256, len(hindi_alpha2index))"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E6LjVKQfoVMU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "outputId": "38b00ea8-a390-42f0-8f65-40b800abeac8"
      },
      "source": [
        "train_setup(net, lr=0.001, n_batches=2000, batch_size = 64, display_freq=10, device = device_gpu)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration 1999 Loss 0.18586304783821106\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.        , 0.47869119, 0.48637506, ..., 0.18589664, 0.18586305,\n",
              "       0.18581009])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GM1Tj20omMi1",
        "colab_type": "text"
      },
      "source": [
        "### Training with Attention "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxFLBqW1Ip4v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net_att = Transliteration_EncoderDecoder_Attention(len(eng_alpha2index), 256, len(hindi_alpha2index))"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdRpJUXNIwuv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "outputId": "aa1a5faa-0ab3-449e-f7ae-e37f0c1285c9"
      },
      "source": [
        "loss_history = train_setup(net_att, lr=0.001, n_batches=2000, batch_size = 64, display_freq=10, device = device_gpu)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration 1999 Loss 0.1431494951248169\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05F1-FwX6YVZ",
        "colab_type": "text"
      },
      "source": [
        "## Inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v3TWC7zhAn3z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test(net, word, device = 'cpu'):\n",
        "    net = net.eval().to(device)\n",
        "    # outputs = infer(net, word, 30, device)\n",
        "    # outputs = infer(net, word, 7, device)\n",
        "    outputs = infer(net, word, 30)\n",
        "    hindi_output = ''\n",
        "    for out in outputs:\n",
        "        val, indices = out.topk(1)\n",
        "        index = indices.tolist()[0][0]\n",
        "        if index == 0:\n",
        "            break\n",
        "        hindi_char = hindi_alphabets[index+1]\n",
        "        hindi_output += hindi_char\n",
        "    print(word + ' - ' + hindi_output)\n",
        "    return hindi_output"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bT8bibYl7CgX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calc_accuracy(net, device = 'cpu'):\n",
        "    net = net.eval().to(device)\n",
        "    predictions = []\n",
        "    accuracy = 0\n",
        "    for i in range(len(test_data)):\n",
        "        eng, hindi = test_data[i]\n",
        "        gt = gt_rep(hindi, hindi_alpha2index, device)\n",
        "        # outputs = infer(net, eng, gt.shape[0], device)\n",
        "        outputs = infer(net, eng, gt.shape[0])\n",
        "        correct = 0\n",
        "        for index, out in enumerate(outputs):\n",
        "            val, indices = out.topk(1)\n",
        "            hindi_pos = indices.tolist()[0]\n",
        "            if hindi_pos[0] == gt[index][0]:\n",
        "                correct += 1\n",
        "        \n",
        "        accuracy += correct/gt.shape[0]\n",
        "    accuracy /= len(test_data)\n",
        "    return accuracy"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dy1bQiORAs5o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "c592c26b-0f7d-4710-cfd2-d7269bab00a1"
      },
      "source": [
        "accuracy = calc_accuracy(net) * 100\n",
        "accuracy_attn = calc_accuracy(net_att) * 100\n",
        "print('Accuracy w/o attention ', accuracy)\n",
        "print('Acurracy with attention', accuracy_attn)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy w/o attention  62.413876678876655\n",
            "Acurracy with attention 70.08765984015986\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hgAL6P-sNOYv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "dee2144b-7d97-4266-9ee1-b6a53a8cbe08"
      },
      "source": [
        "out1 = infer(net, 'INDIA', 7)\n",
        "out2 = infer(net_attn, 'INDIA', 7)\n",
        "\n",
        "print(len(out1))\n",
        "for i in range(len(out1)):\n",
        "    print(out1[i].shape, list(hindi_alpha2index.keys())[list(hindi_alpha2index.values()).index(torch.argmax(out1[i]))])\n",
        "\n",
        "print(len(out2))\n",
        "for i in range(len(out2)):\n",
        "    print(out2[i].shape, list(hindi_alpha2index.keys())[list(hindi_alpha2index.values()).index(torch.argmax(out2[i]))])"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7\n",
            "torch.Size([1, 129]) इ\n",
            "torch.Size([1, 129]) ं\n",
            "torch.Size([1, 129]) ड\n",
            "torch.Size([1, 129]) ि\n",
            "torch.Size([1, 129]) य\n",
            "torch.Size([1, 129]) ा\n",
            "torch.Size([1, 129]) -PAD-\n",
            "7\n",
            "torch.Size([1, 129]) ३\n",
            "torch.Size([1, 129]) ॐ\n",
            "torch.Size([1, 129]) ॐ\n",
            "torch.Size([1, 129]) घ\n",
            "torch.Size([1, 129]) ३\n",
            "torch.Size([1, 129]) ॐ\n",
            "torch.Size([1, 129]) घ\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ukoNAs8wP-GH",
        "colab_type": "text"
      },
      "source": [
        "## Exercises\n",
        "\n",
        "1. Train longer and check accuracy - play with different hyperparameters\n",
        "2. Visualise attention - which part of the encoder output are we attending to\n",
        "3. Improve performance with batching - use the packing idea from earlier\n",
        "4. Try other attention mechanisms\n"
      ]
    }
  ]
}